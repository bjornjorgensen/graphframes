name: Scala CI
on: [push, pull_request]
jobs:
  test:
    strategy:
      fail-fast: false
      matrix:
        include:
          - spark-version: 3.5.4
            scala-version: 2.13.8
          - spark-version: 3.5.0
            scala-version: 2.12.12
    runs-on: ubuntu-22.04
    env:
      # JVM settings
      JAVA_OPTS: -Xms4096M -Xmx4096M -Xss6M -XX:ReservedCodeCacheSize=512M -XX:+CMSClassUnloadingEnabled -XX:+UseConcMarkSweepGC -Dfile.encoding=UTF-8
      JVM_OPTS:  -Xms4096M -Xmx4096M -Xss6M -XX:ReservedCodeCacheSize=512M -XX:+CMSClassUnloadingEnabled -XX:+UseConcMarkSweepGC -Dfile.encoding=UTF-8
      SBT_OPTS: -Xms4096M -Xmx4096M -Xss6M -XX:ReservedCodeCacheSize=512M -XX:+CMSClassUnloadingEnabled
      # Spark test configuration
      SPARK_LOCAL_IP: 127.0.0.1
      SPARK_DRIVER_MEMORY: 4g
      SPARK_WORKER_MEMORY: 4g
      SPARK_EXECUTOR_MEMORY: 4g
      SPARK_EXECUTOR_CORES: 2
      SPARK_WORKER_CORES: 2
      SPARK_TESTING: 1
    steps:
    - uses: actions/checkout@v4
    - uses: olafurpg/setup-scala@v13
      with:
        java-version: "openjdk@1.11"
    - uses: actions/cache@v4
      with:
        path: |
          ~/.ivy2/cache
        key: sbt-ivy-cache-spark-${{ matrix.spark-version}}-scala-${{ matrix.scala-version }}
    - name: Build and Test
      run: |
        build/sbt -v ++${{ matrix.scala-version }} \
        -Dspark.version=${{ matrix.spark-version }} \
        -Dspark.master=local[2] \
        -Dspark.sql.adaptive.enabled=false \
        -Dspark.sql.adaptive.coalescePartitions.enabled=false \
        -Dspark.sql.adaptive.localShuffleReader.enabled=false \
        -Dspark.sql.exchange.reuse=false \
        -Dspark.sql.autoBroadcastJoinThreshold=-1 \
        -Dspark.sql.analyzer.failAmbiguousSelfJoin=false \
        -Dspark.sql.optimizer.runtimeOptimization=false \
        coverage test coverageReport
    - uses: codecov/codecov-action@v3
