name: Python CI
on: [push, pull_request]
jobs:
  test:
    strategy:
      fail-fast: false
      matrix:
        spark-version: [3.5.4]
        scala-version: [2.12.18]
        python-version: [3.9.19]
        java: [8, 11, 17]
    runs-on: ubuntu-22.04
    env:
      # define Java options for both official sbt and sbt-extras
      JAVA_OPTS: -Xms2048M -Xmx2048M -Xss6M -XX:ReservedCodeCacheSize=256M --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.math=ALL-UNNAMED -Dfile.encoding=UTF-8
      JVM_OPTS:  -Xms2048M -Xmx2048M -Xss6M -XX:ReservedCodeCacheSize=256M --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.math=ALL-UNNAMED -Dfile.encoding=UTF-8
      SPARK_VERSION: ${{ matrix.spark-version }}
      SCALA_VERSION: ${{ matrix.scala-version }}
    steps:
    - uses: actions/checkout@v4
    - uses: actions/setup-java@v4
      with:
        distribution: 'temurin'
        java-version: ${{ matrix.java }}
        cache: 'sbt'
    - name: Set Java Options
      run: |
        JAVA_MAJOR_VERSION=$($JAVA_HOME/bin/java -version 2>&1 | head -n 1 | cut -d'"' -f2 | cut -d'.' -f1)
        if [ "$JAVA_MAJOR_VERSION" -ge "9" ]; then
          echo "JAVA_OPTS=-Xms2048M -Xmx2048M -Xss6M -XX:ReservedCodeCacheSize=256M --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.math=ALL-UNNAMED -Dfile.encoding=UTF-8" >> $GITHUB_ENV
          echo "JVM_OPTS=-Xms2048M -Xmx2048M -Xss6M -XX:ReservedCodeCacheSize=256M --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.math=ALL-UNNAMED -Dfile.encoding=UTF-8" >> $GITHUB_ENV
        else
          echo "JAVA_OPTS=-Xms2048M -Xmx2048M -Xss6M -XX:ReservedCodeCacheSize=256M -Dfile.encoding=UTF-8" >> $GITHUB_ENV
          echo "JVM_OPTS=-Xms2048M -Xmx2048M -Xss6M -XX:ReservedCodeCacheSize=256M -Dfile.encoding=UTF-8" >> $GITHUB_ENV
        fi
    - uses: actions/cache@v4
      with:
        path: |
          ~/.ivy2/cache
        key: sbt-ivy-cache-spark-${{ matrix.spark-version}}-scala-${{ matrix.scala-version }}
    - uses: olafurpg/setup-scala@v13
      with:
        java-version: "openjdk@1.11"
    - name: Assembly
      run: build/sbt -v ++${{ matrix.scala-version }} -Dspark.version=${{ matrix.spark-version }} "set test in assembly := {}" assembly
    - uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}
    - name: Install python dependencies
      run: |
        python -m pip install --upgrade pip wheel
        pip install -r ./python/requirements.txt
        pip install pyspark==${{ matrix.spark-version }}
    - name: Test
      run: |
        export SPARK_HOME=$(python -c "import os; from importlib.util import find_spec; print(os.path.join(os.path.dirname(find_spec('pyspark').origin)))")
        ./python/run-tests.sh
